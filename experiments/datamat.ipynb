{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataMat- 0.1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import traceback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import HuggingFaceHub, LLMChain\n",
    "from langchain_huggingface import HuggingFaceEndpoint\n",
    "from langchain.callbacks import StdOutCallbackHandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback_handler = StdOutCallbackHandler()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "KEY = os.getenv(\"HUGGINGFACEHUB_API_TOKEN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"mistralai/Mistral-7B-Instruct-v0.3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! max_lenght is not default parameter.\n",
      "                    max_lenght was transferred to model_kwargs.\n",
      "                    Please make sure that max_lenght is what you intended.\n",
      "WARNING! token is not default parameter.\n",
      "                    token was transferred to model_kwargs.\n",
      "                    Please make sure that token is what you intended.\n",
      "WARNING! device is not default parameter.\n",
      "                    device was transferred to model_kwargs.\n",
      "                    Please make sure that device is what you intended.\n",
      "/home/voidreaper/Projects/datamat/env/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "llm = HuggingFaceEndpoint(repo_id= model_id, max_lenght = 128, temperature=0.7, token =KEY, device = \"auto\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HuggingFaceEndpoint(repo_id='mistralai/Mistral-7B-Instruct-v0.3', temperature=0.7, model_kwargs={'max_lenght': 128, 'token': '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', 'device': 'auto'}, model='mistralai/Mistral-7B-Instruct-v0.3', client=<InferenceClient(model='mistralai/Mistral-7B-Instruct-v0.3', timeout=120)>, async_client=<InferenceClient(model='mistralai/Mistral-7B-Instruct-v0.3', timeout=120)>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Not much, really.\n",
      "\n",
      "We are both human beings, sharing the same planet.\n",
      "\n",
      "We are both made up of the same elements.\n",
      "\n",
      "We are both capable of love, of joy, of sorrow, of anger.\n",
      "\n",
      "We are both capable of kindness, of cruelty, of compassion, of indifference.\n",
      "\n",
      "We are both capable of greatness, of mediocrity, of failure, of success.\n",
      "\n",
      "We are both capable of changing the world, or of leaving it unchanged.\n",
      "\n",
      "The difference between us is not in our essence, but in our choices.\n",
      "\n",
      "I choose to see the world as a place of abundance, of endless possibilities, of endless opportunities.\n",
      "\n",
      "I choose to see others as my brothers and sisters, deserving of my love and respect.\n",
      "\n",
      "I choose to see myself as a creator, as someone who can make a difference, who can leave a legacy.\n",
      "\n",
      "I choose to see failure as a stepping stone, not as a dead end.\n",
      "\n",
      "I choose to see challenges as opportunities, not as obstacles.\n",
      "\n",
      "I choose to see the glass as half full, not half empty.\n",
      "\n",
      "I choose to see the best in people, not their worst.\n",
      "\n",
      "I choose to see the good in the world, not the bad.\n",
      "\n",
      "I choose to see the beauty in the world, not the ugliness.\n",
      "\n",
      "I choose to see the light, not the darkness.\n",
      "\n",
      "I choose to see the possibilities, not the limitations.\n",
      "\n",
      "I choose to see the potential, not the impossibility.\n",
      "\n",
      "I choose to see the hope, not the despair.\n",
      "\n",
      "I choose to see the love, not the hate.\n",
      "\n",
      "I choose to see the peace, not the war.\n",
      "\n",
      "I choose to see the joy, not the sorrow.\n",
      "\n",
      "I choose to see the goodness, not the evil.\n",
      "\n",
      "I choose to see the kindness, not the cruelty.\n",
      "\n",
      "I choose to see the compassion, not the indifference.\n",
      "\n",
      "I choose to see the greatness, not the mediocrity.\n",
      "\n",
      "I choose to see the success, not the failure.\n",
      "\n",
      "I choose to see the world as a place of infinite potential, where anything is possible, where every person has the power to make a difference, where every choice matters.\n",
      "\n",
      "I choose to see myself as a creator, as someone who can make a difference\n"
     ]
    }
   ],
   "source": [
    "print(llm.invoke(\"What is the difference between you and me?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import HuggingFaceHub\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import SequentialChain\n",
    "\n",
    "import PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMPLATE_EDA = \"\"\"\n",
    "Analyze the given dataset and provide key statistics, including:\n",
    "- Number of rows and columns.\n",
    "- Summary statistics (mean, median, std, etc.) for numerical columns.\n",
    "- Distribution of categorical columns.\n",
    "- Detect missing values and duplicates.\n",
    "Respond in JSON format.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESPONSE_JSON_EDA = {\n",
    "  \"summary\": {\n",
    "    \"rows\": 1000,\n",
    "    \"columns\": 20,\n",
    "    \"numerical_columns\": {\n",
    "      \"col1\": { \"mean\": 50, \"std\": 10, \"min\": 10, \"max\": 100 },\n",
    "      \"col2\": { \"mean\": 5.6, \"std\": 0.8, \"min\": 2, \"max\": 9 }\n",
    "    },\n",
    "    \"categorical_columns\": {\n",
    "      \"col3\": { \"unique_values\": [\"A\", \"B\", \"C\"], \"frequencies\": { \"A\": 500, \"B\": 300, \"C\": 200 } }\n",
    "    },\n",
    "    \"missing_values\": { \"col1\": 5, \"col2\": 0, \"col3\": 10 },\n",
    "    \"duplicates\": 2\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "eda_generation_prompt = PromptTemplate(\n",
    "    input_variables=[\"dataset\", \"response_json\"],\n",
    "    template=TEMPLATE_EDA\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_155520/1434336669.py:1: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use RunnableSequence, e.g., `prompt | llm` instead.\n",
      "  eda_chain = LLMChain(\n"
     ]
    }
   ],
   "source": [
    "eda_chain = LLMChain(\n",
    "    llm=llm,  # Initialize your LLM (e.g., OpenAI, Hugging Face, etc.)\n",
    "    prompt=eda_generation_prompt,\n",
    "    output_key=\"eda_analysis\",\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_155520/3371726697.py:1: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use invoke instead.\n",
      "  response_eda = eda_chain.run(\n",
      "Error in StdOutCallbackHandler.on_chain_start callback: AttributeError(\"'NoneType' object has no attribute 'get'\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Analyze the given dataset and provide key statistics, including:\n",
      "- Number of rows and columns.\n",
      "- Summary statistics (mean, median, std, etc.) for numerical columns.\n",
      "- Distribution of categorical columns.\n",
      "- Detect missing values and duplicates.\n",
      "Respond in JSON format.\n",
      "\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "response_eda = eda_chain.run(\n",
    "    dataset=\"/home/voidreaper/Projects/datamat/experiments/iris.csv\", \n",
    "    response_json=RESPONSE_JSON_EDA\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "  \"dataset_info\": {\n",
      "    \"rows\": 1000,\n",
      "    \"columns\": 5,\n",
      "    \"columns_names\": [\"Age\", \"Gender\", \"Income\", \"Education\", \"Marital Status\"]\n",
      "  },\n",
      "  \"summary_statistics\": {\n",
      "    \"Age\": {\n",
      "      \"mean\": 35.2,\n",
      "      \"median\": 34,\n",
      "      \"std\": 9.6,\n",
      "      \"min\": 18,\n",
      "      \"max\": 68,\n",
      "      \"quartiles\": [24, 41, 50]\n",
      "    },\n",
      "    \"Income\": {\n",
      "      \"mean\": 52000,\n",
      "      \"median\": 50000,\n",
      "      \"std\": 11000,\n",
      "      \"min\": 25000,\n",
      "      \"max\": 80000,\n",
      "      \"quartiles\": [35000, 55000, 60000]\n",
      "    }\n",
      "  },\n",
      "  \"categorical_distribution\": {\n",
      "    \"Gender\": {\n",
      "      \"Male\": 580,\n",
      "      \"Female\": 420\n",
      "    },\n",
      "    \"Education\": {\n",
      "      \"High School\": 230,\n",
      "      \"Some College\": 320,\n",
      "      \"Bachelor's Degree\": 350,\n",
      "      \"Master's Degree\": 100\n",
      "    },\n",
      "    \"Marital Status\": {\n",
      "      \"Single\": 500,\n",
      "      \"Married\": 400,\n",
      "      \"Divorced\": 80,\n",
      "      \"Widowed\": 20\n",
      "    }\n",
      "  },\n",
      "  \"missing_values\": {\n",
      "    \"Age\": 0,\n",
      "    \"Gender\": 0,\n",
      "    \"Income\": 0,\n",
      "    \"Education\": 0,\n",
      "    \"Marital Status\": 0\n",
      "  },\n",
      "  \"duplicates\": {\n",
      "    \"Age\": 0,\n",
      "    \"Gender\": 0,\n",
      "    \"Income\": 0,\n",
      "    \"Education\":\n"
     ]
    }
   ],
   "source": [
    "print(response_eda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMPLATE_EDA_REVIEW = \"\"\"\n",
    "You are an AI assistant reviewing the results of a dataset analysis.\n",
    "Given the response JSON, validate the following:\n",
    "- Is the JSON correctly formatted?\n",
    "- Do the \"rows\" and \"columns\" values match the dataset dimensions?\n",
    "- Are the summary statistics (mean, median, std, etc.) plausible for the numerical columns?\n",
    "- Are the unique values and frequencies reasonable for categorical columns?\n",
    "- Is the number of missing values accurately reported?\n",
    "- Are duplicates identified correctly?\n",
    "\n",
    "Respond with a JSON object containing:\n",
    "- \"validity\" (Valid/Invalid)\n",
    "- \"issues\" (List of identified issues, if any)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_metadata = {\n",
    "    \"rows\": 1000,\n",
    "    \"columns\": 20,\n",
    "    \"numerical_columns\": [\"col1\", \"col2\"],\n",
    "    \"categorical_columns\": [\"col3\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_prompt = PromptTemplate(\n",
    "    input_variables=[\"response_json\", \"dataset_metadata\"],\n",
    "    template=TEMPLATE_EDA_REVIEW\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_chain = LLMChain(\n",
    "    llm=llm,  # Use the same LLM\n",
    "    prompt=review_prompt,\n",
    "    output_key=\"review_analysis\",\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in StdOutCallbackHandler.on_chain_start callback: AttributeError(\"'NoneType' object has no attribute 'get'\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "You are an AI assistant reviewing the results of a dataset analysis.\n",
      "Given the response JSON, validate the following:\n",
      "- Is the JSON correctly formatted?\n",
      "- Do the \"rows\" and \"columns\" values match the dataset dimensions?\n",
      "- Are the summary statistics (mean, median, std, etc.) plausible for the numerical columns?\n",
      "- Are the unique values and frequencies reasonable for categorical columns?\n",
      "- Is the number of missing values accurately reported?\n",
      "- Are duplicates identified correctly?\n",
      "\n",
      "Respond with a JSON object containing:\n",
      "- \"validity\" (Valid/Invalid)\n",
      "- \"issues\" (List of identified issues, if any)\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "response_review = review_chain.run(\n",
    "    response_json=response_eda, \n",
    "    dataset_metadata=dataset_metadata\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Example JSON response:\n",
      "{\n",
      "  \"validity\": \"Valid\",\n",
      "  \"issues\": []\n",
      "}\n",
      "\n",
      "JSON Response:\n",
      "\n",
      "{\n",
      "  \"validity\": \"Valid\",\n",
      "  \"issues\": []\n",
      "}\n",
      "\n",
      "Explanation:\n",
      "\n",
      "- The JSON is correctly formatted, as it is a valid JSON object with two properties: \"validity\" and \"issues\".\n",
      "- The \"rows\" and \"columns\" values (assuming they were provided) match the dataset dimensions, as there are no values provided in the given JSON to validate this.\n",
      "- The summary statistics (mean, median, std, etc.) for the numerical columns are not provided in the given JSON to validate their plausibility. However, if they were provided, they could be checked for reasonableness based on the specific dataset and its expected distribution.\n",
      "- The unique values and frequencies for categorical columns are not provided in the given JSON to validate their reasonableness. However, if they were provided, they could be checked for reasonableness based on the specific dataset and its expected distribution.\n",
      "- The number of missing values is not provided in the given JSON to verify its accuracy. However, if it were provided, it could be checked for accuracy based on the actual number of missing values in the dataset.\n",
      "- Duplicates are not identified in the given JSON, as there is no property for this in the JSON. If there were a property for duplicates, it could be checked for accuracy based on the actual number of duplicates in the dataset.\n",
      "\n",
      "Therefore, the JSON response indicates that the analysis results are valid, as no issues were identified in the provided JSON.\n"
     ]
    }
   ],
   "source": [
    "print(response_review)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequential_chain = SequentialChain(\n",
    "    chains=[eda_chain, review_chain],  # First generate, then review\n",
    "    input_variables=[\"dataset\", \"dataset_metadata\"],\n",
    "    output_variables=[\"eda_analysis\", \"review_analysis\"],\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for SequentialChain\n__root__\n  Expected output variables that were not found: {'review_eda_analysis'}. (type=value_error)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m generate_evaluate_chain \u001b[38;5;241m=\u001b[39m \u001b[43mSequentialChain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchains\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m        \u001b[49m\u001b[43meda_chain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m                 \u001b[49m\u001b[38;5;66;43;03m# Exploratory Data Analysis\u001b[39;49;00m\n\u001b[1;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreview_chain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Review Visualizations\u001b[39;49;00m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_variables\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdataset\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdataset_metadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_variables\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meda_analysis\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreview_eda_analysis\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m       \u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mcallback_handler\u001b[49m\u001b[43m]\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Add callback handler for monitoring\u001b[39;49;00m\n\u001b[1;32m     14\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/datamat/env/lib/python3.8/site-packages/langchain_core/load/serializable.py:113\u001b[0m, in \u001b[0;36mSerializable.__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    112\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\"\"\"\u001b[39;00m\n\u001b[0;32m--> 113\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/datamat/env/lib/python3.8/site-packages/pydantic/v1/main.py:341\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[0;34m(__pydantic_self__, **data)\u001b[0m\n\u001b[1;32m    339\u001b[0m values, fields_set, validation_error \u001b[38;5;241m=\u001b[39m validate_model(__pydantic_self__\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m, data)\n\u001b[1;32m    340\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m validation_error:\n\u001b[0;32m--> 341\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m validation_error\n\u001b[1;32m    342\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    343\u001b[0m     object_setattr(__pydantic_self__, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__dict__\u001b[39m\u001b[38;5;124m'\u001b[39m, values)\n",
      "\u001b[0;31mValidationError\u001b[0m: 1 validation error for SequentialChain\n__root__\n  Expected output variables that were not found: {'review_eda_analysis'}. (type=value_error)"
     ]
    }
   ],
   "source": [
    "generate_evaluate_chain = SequentialChain(\n",
    "    chains=[\n",
    "        eda_chain,                 # Exploratory Data Analysis\n",
    "        review_chain,          # Review EDA\n",
    "        \n",
    "        corr_patt_chain,           # Correlations and Patterns Analysis\n",
    "        corr_patt_review_chain,    # Review Correlations and Patterns\n",
    "        \n",
    "        tva_chain,                 # Target Variable Analysis\n",
    "        tva_review_chain,          # Review Target Variable Analysis\n",
    "        \n",
    "        imp_feat_chain,            # Important Features Identification\n",
    "        imp_feat_review_chain,     # Review Important Features\n",
    "        \n",
    "        vsul_chain,                # Visualizations Generation\n",
    "        vsul_review_chain          # Review Visualizations\n",
    "    ],\n",
    "    input_variables=[\"dataset\", \"dataset_metadata\"],\n",
    "    output_variables=[\n",
    "        \"eda_analysis\", \n",
    "        \"review_eda_analysis\",\n",
    "        \"correlation_patterns\", \n",
    "        \"review_correlation_patterns\",\n",
    "        \"target_variable_analysis\", \n",
    "        \"review_target_variable_analysis\",\n",
    "        \"important_features\", \n",
    "        \"review_important_features\",\n",
    "        \"visualizations\", \n",
    "        \"review_visualizations\"\n",
    "    ],\n",
    "    verbose=True,\n",
    "    callbacks=[callback_handler]  # Add callback handler for monitoring\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMPLATE_CORR_PATT = \"\"\"\n",
    "Analyze the correlations between features in the dataset:\n",
    "- Provide a correlation matrix.\n",
    "- Identify features with strong positive or negative correlations (threshold = 0.7).\n",
    "- Highlight evident patterns or trends.\n",
    "Respond in JSON format.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESPONSE_JSON_CORR_PAT = {\n",
    "  \"correlation_matrix\": {\n",
    "    \"col1\": { \"col1\": 1.0, \"col2\": 0.85, \"col3\": -0.2 },\n",
    "    \"col2\": { \"col1\": 0.85, \"col2\": 1.0, \"col3\": 0.1 },\n",
    "    \"col3\": { \"col1\": -0.2, \"col2\": 0.1, \"col3\": 1.0 }\n",
    "  },\n",
    "  \"strong_correlations\": [\n",
    "    { \"feature1\": \"col1\", \"feature2\": \"col2\", \"correlation\": 0.85 }\n",
    "  ],\n",
    "  \"patterns\": \"Feature col1 increases as col2 increases. Feature col3 has no strong trend.\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMPLATE_TVA = \"\"\"\n",
    "Analyze the distribution of the target variable and its relationships with other features:\n",
    "- Provide summary statistics and visual distribution insights.\n",
    "- Identify correlations with other features.\n",
    "Respond in JSON format.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESPONSE_JSON_TVA = {\n",
    "  \"target_variable\": {\n",
    "    \"name\": \"target\",\n",
    "    \"distribution\": { \"mean\": 5, \"std\": 1.2, \"min\": 1, \"max\": 10 },\n",
    "    \"correlations\": [\n",
    "      { \"feature\": \"col1\", \"correlation\": 0.8 },\n",
    "      { \"feature\": \"col2\", \"correlation\": -0.5 }\n",
    "    ]\n",
    "  }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMPLATE_IMP_FEAT = \"\"\"Extract the most important features for predicting the target variable and generate predictions:\n",
    "- Provide the top 5 features with importance scores.\n",
    "- Predict outcomes for the first 10 rows in the dataset.\n",
    "Respond in JSON format.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESPONSE_JSON_IMP_FEAT = {\n",
    "  \"feature_importance\": [\n",
    "    { \"feature\": \"col1\", \"importance\": 0.4 },\n",
    "    { \"feature\": \"col2\", \"importance\": 0.3 },\n",
    "    { \"feature\": \"col3\", \"importance\": 0.2 },\n",
    "    { \"feature\": \"col4\", \"importance\": 0.1 }\n",
    "  ],\n",
    "  \"predictions\": {\n",
    "    \"row1\": 5.4,\n",
    "    \"row2\": 6.2,\n",
    "    \"row3\": 4.9,\n",
    "    \"row4\": 5.1,\n",
    "    \"row5\": 5.7\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMPLATE_VSUL = \"\"\"Generate visualizations for the dataset:\n",
    "- Histogram for numerical columns.\n",
    "- Heatmap for correlations.\n",
    "- Bar chart for target variable distribution.\n",
    "Provide a description of the visualizations generated in JSON format.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESPONSE_JSON_IMP_VSUL = {\n",
    "  \"visualizations\": [\n",
    "    { \"type\": \"histogram\", \"columns\": [\"col1\", \"col2\"], \"description\": \"Distribution of numerical columns.\" },\n",
    "    { \"type\": \"heatmap\", \"description\": \"Correlation heatmap for all features.\" },\n",
    "    { \"type\": \"bar_chart\", \"column\": \"target\", \"description\": \"Target variable distribution.\" }\n",
    "  ]\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "undefined.undefined.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
